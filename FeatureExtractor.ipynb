{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb63b743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romitbarua/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/romitbarua/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/romitbarua/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#general packages\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "import json\n",
    "import pickle\n",
    "from ast import literal_eval\n",
    "import random\n",
    "\n",
    "#dataframe and data science packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#nltk packages\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#gensim packages\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#emotion detection packages\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import text2emotion as te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d33ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ChordFeaturizer.ipynb\n",
    "%run LdaFeaturizer.ipynb\n",
    "%run GeneralLyricsFeaturizer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c72d3",
   "metadata": {},
   "source": [
    "# Import the Cleaned DataFrame\n",
    "\n",
    "## Will be used to generate our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b865ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regenerate the DF if new data has been added or other changes have been made to GenerateCleanDF\n",
    "regenerateDF = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f2b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "if regenerateDF == 1:\n",
    "    print('Generating New DF:')\n",
    "    %run GenerateCleanDF.ipynb\n",
    "    print('New DF Generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef163b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Clean DF -> Completed Import\n"
     ]
    }
   ],
   "source": [
    "print('Importing Clean DF -> ', end='')\n",
    "pickle_in = open(\"Clean_DF.pickle\",\"rb\")\n",
    "df = pickle.load(pickle_in)\n",
    "\n",
    "df = df.rename(columns={'index':'track_name'})\n",
    "print('Completed Import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1d2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Final_DF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f976b",
   "metadata": {},
   "source": [
    "# Build Bag of Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f0c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBowFeatures(BowType, Tfidf, runSVD):\n",
    "    print('Building BoW Features -> ', end='')\n",
    "    \n",
    "    if BowType == 'Lyrics':\n",
    "        vocab, trainX, testX = buildBoW(df.loc[:,'clean_lyrics'].tolist())\n",
    "    elif BowType == 'Chords':\n",
    "        chord_list = df.clean_tabs.tolist()\n",
    "        chord_list = [song_chord.replace(',', ' ') for song_chord in chord_list]\n",
    "        \n",
    "        #buildBoW(lyrics_list, Tfidf = False, runSVD = 0, num_components = 100, train_perc=0.8):\n",
    "        vocab, trainX, testX = buildBoW(chord_list, runSVD)\n",
    "    print('BoW Features Built')\n",
    "    \n",
    "    return vocab, trainX, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025a60a",
   "metadata": {},
   "source": [
    "# Build the Chord Progression Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a51592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildChordProgressionFeatures(key_col, chordNormType, ngram_low, ngram_high, binary, runSVD, Tfidf, num_components, min_df):\n",
    "    print('Building Chord Progression Features -> ', end='')\n",
    "\n",
    "    full, partial, bare = buildNormTab(df, key_col)\n",
    "    \n",
    "    if chordNormType == 'Full':\n",
    "        chords = full\n",
    "    elif chordNormType == 'Partial':\n",
    "        chords = partial\n",
    "    elif chordNormType == 'Bare':\n",
    "        chords = bare\n",
    "    #vectorizeTab(chords, ngram_low, ngram_high,  binary, Tfidf = False, runSVD = 0, num_components = 100, train_perc = 0.8, min_df = 5)\n",
    "    print(num_components)\n",
    "    vocab, trainX, testX = vectorizeTab(chords, ngram_low, ngram_high, binary, Tfidf, runSVD, num_components = num_components, min_df = min_df)\n",
    "    \n",
    "    print('Chord Progression Features Built')\n",
    "    \n",
    "    return vocab, trainX, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e17f3d",
   "metadata": {},
   "source": [
    "# Build LDA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52749a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLdaFeatures(num_topics = 50, train_perc = 0.8):\n",
    "    \n",
    "    train_break = int(len(df)*train_perc)\n",
    "    print('Building LDA Features -> ', end='')\n",
    "    \n",
    "    topics, LdaFeatures = buildFeatures(df, num_topics)\n",
    "\n",
    "    trainX, testX = csr_matrix(LdaFeatures[:train_break]), csr_matrix(LdaFeatures[train_break:])\n",
    "    \n",
    "    print('LDA Features Built')\n",
    "    \n",
    "    return topics, trainX, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccc9d02",
   "metadata": {},
   "source": [
    "# Build Emotion Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30ac9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildEmotionFeatures(emotionFeatureType, train_perc = 0.8):\n",
    "    print('Building Emotion Features -> ', end='')\n",
    "    \n",
    "    train_break = int(len(df)*train_perc)\n",
    "    \n",
    "    if emotionFeatureType == 'Vader':\n",
    "        feature = [list(song.values()) for song in list(df['vader_emotion'])]\n",
    "    else:\n",
    "        feature = [list(song.values()) for song in list(df['text2emotion'])]\n",
    "        \n",
    "    trainX, testX = csr_matrix(feature[:train_break]), csr_matrix(feature[train_break:])\n",
    "    \n",
    "    print('Emotion Features Built')\n",
    "    return trainX, testX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef6dd26",
   "metadata": {},
   "source": [
    "# Build Text Complexity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a6bc1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTextComplexityFeatures(train_perc = 0.8):\n",
    "    print('Building Text Complexty Features -> ', end='')\n",
    "\n",
    "    train_break = int(len(df)*train_perc)\n",
    "    \n",
    "    text_complexity_feature = []\n",
    "    for i in range(len(df)):\n",
    "        text_complexity_feature.append(buildTypeTokenRatio(df.clean_lyrics[i]))\n",
    "\n",
    "    trainX, testX = csr_matrix(text_complexity_feature[:train_break]), csr_matrix(text_complexity_feature[train_break:])\n",
    "    \n",
    "    print('Text Complexity Features Built')\n",
    "    return trainX, testX\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d96d3",
   "metadata": {},
   "source": [
    "# Build Train & Test Prediction Series (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c51e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildY(predAttribute, randomY = False, train_perc = 0.8):\n",
    "    train_break = int(len(df)*train_perc)\n",
    "    \n",
    "    pred_list = df.loc[:, predAttribute].tolist()\n",
    "    \n",
    "    if randomY:\n",
    "        random.shuffle(pred_list)\n",
    "    \n",
    "    trainy, testy = pred_list[:train_break], pred_list[train_break:]\n",
    "    return trainy, testy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ce6ac",
   "metadata": {},
   "source": [
    "# Check the Feature Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47ec24c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab, vectorTrain, vectorTest = vectorizeTab(firstNote_full, 3, 3, True, 0.8)\\n#print(vectorTrain)\\nvectorTrain, vectorTest, vocab = cleanForDocFequency(vectorTrain, vectorTest, vocab, 1, 10)\\nprint(vectorTrain.shape)\\nprint(vectorTest.shape)    \\nprint(len(vocab))\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"vocab, vectorTrain, vectorTest = vectorizeTab(firstNote_full, 3, 3, True, 0.8)\n",
    "#print(vectorTrain)\n",
    "vectorTrain, vectorTest, vocab = cleanForDocFequency(vectorTrain, vectorTest, vocab, 1, 10)\n",
    "print(vectorTrain.shape)\n",
    "print(vectorTest.shape)    \n",
    "print(len(vocab))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
